[
    {
        "content": "<p>Hi,<br>\nI'm installing zulip and get this error:</p>\n<div class=\"codehilite\"><pre><span></span><code>Django cannot connect to Tornado server. (http://127.0.0.1:9993); try restarting\n</code></pre></div>\n<p>Could help me, please?</p>",
        "id": 1061867,
        "sender_full_name": "wekun",
        "timestamp": 1605137712
    },
    {
        "content": "<p>Is this a production installation or a development environment?</p>",
        "id": 1061868,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605138160
    },
    {
        "content": "<p>our production zulip server</p>",
        "id": 1061869,
        "sender_full_name": "wekun",
        "timestamp": 1605138218
    },
    {
        "content": "<p>the connection is up/down every time</p>",
        "id": 1061870,
        "sender_full_name": "wekun",
        "timestamp": 1605138276
    },
    {
        "content": "<p>I ask because port 9993 is only used in the development environment—are you using the development environment as a “production” server?</p>",
        "id": 1061871,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605138346
    },
    {
        "content": "<p>ok, thanks Anders!</p>",
        "id": 1061872,
        "sender_full_name": "wekun",
        "timestamp": 1605138389
    },
    {
        "content": "<p>You really shouldn’t do that because the development environment is slower and deliberately insecure.</p>",
        "id": 1061873,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605138442
    },
    {
        "content": "<p>please, where i can read about how i do the setup for production?</p>",
        "id": 1061874,
        "sender_full_name": "wekun",
        "timestamp": 1605138449
    },
    {
        "content": "<p><a href=\"https://zulip.readthedocs.io/en/stable/production/\">https://zulip.readthedocs.io/en/stable/production/</a></p>",
        "id": 1061875,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605138474
    },
    {
        "content": "<p>ok, thanks</p>",
        "id": 1061876,
        "sender_full_name": "wekun",
        "timestamp": 1605138499
    },
    {
        "content": "<p>I follow stable -&gt; production documentation. But I don't see where setup for correct this error.<br>\nFrom error log:</p>\n<div class=\"codehilite\"><pre><span></span><code> requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#39;127.0.0.1&#39;, port=9993):\nMax retries exceeded with url: /api/v1/events/internal (Caused by\nNewConnectionError(&#39;&lt;urllib3.connection.HTTPConnection object at 0x7f0b8f65fa90&gt;:\nFailed to establish  a new connection: [Errno 111] Connection refused&#39;))\n</code></pre></div>",
        "id": 1061879,
        "sender_full_name": "wekun",
        "timestamp": 1605139382
    },
    {
        "content": "<p>and</p>\n<div class=\"codehilite\"><pre><span></span><code>f&quot;Django cannot connect to Tornado server ({tornado_uri}); try restarting&quot;)\nrequests.exceptions.ConnectionError: Django cannot connect to Tornado server\n(http://127.0.0.1:9993); try restarting\n</code></pre></div>",
        "id": 1061880,
        "sender_full_name": "wekun",
        "timestamp": 1605139471
    },
    {
        "content": "<p>i install latest release:</p>\n<div class=\"codehilite\"><pre><span></span><code>wget https://www.zulip.org/dist/releases/zulip-server-latest.tar.gz\n</code></pre></div>",
        "id": 1061881,
        "sender_full_name": "wekun",
        "timestamp": 1605140167
    },
    {
        "content": "<p>Unless you have manually configured port 9993 somewhere, I don’t think there’s any way to get such an error involving port 9993 unless you’re still using the development environment.</p>",
        "id": 1061882,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605140674
    },
    {
        "content": "<p>What is the full path to the log file where you found that error?</p>",
        "id": 1061883,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605140792
    },
    {
        "content": "<p>I don't put port 9993</p>",
        "id": 1061884,
        "sender_full_name": "wekun",
        "timestamp": 1605140852
    },
    {
        "content": "<p>I'm sure</p>",
        "id": 1061885,
        "sender_full_name": "wekun",
        "timestamp": 1605140861
    },
    {
        "content": "<p>And? What is the full path to the log file where you found that error?</p>",
        "id": 1061886,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605141145
    },
    {
        "content": "<p>tail -f /var/log/zulip/errors.log</p>",
        "id": 1061887,
        "sender_full_name": "wekun",
        "timestamp": 1605141145
    },
    {
        "content": "<p>I don't create a new zulip organization. I migrate mattermost organization</p>",
        "id": 1061888,
        "sender_full_name": "wekun",
        "timestamp": 1605141651
    },
    {
        "content": "<p>Can you paste the output of <code>supervisorctl status</code> and <code>netstat -tlpn</code>?</p>",
        "id": 1061889,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605141979
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>supervisorctl status\nprocess-fts-updates                              RUNNING   pid 27145, uptime 0:45:58\nzulip-django                                     RUNNING   pid 27143, uptime 0:45:58\nzulip-tornado                                    RUNNING   pid 16188, uptime 0:00:40\nzulip-workers:zulip_deliver_enqueued_emails      RUNNING   pid 15849, uptime 0:01:31\nzulip-workers:zulip_deliver_scheduled_messages   RUNNING   pid 16324, uptime 0:00:32\nzulip-workers:zulip_events                       RUNNING   pid 15877, uptime 0:00:54\n</code></pre></div>",
        "id": 1061890,
        "sender_full_name": "wekun",
        "timestamp": 1605142086
    },
    {
        "content": "<p><code>zulip-tornado</code> has only been running for 40 seconds? Have you checked /var/log/zulip/tornado.log?</p>",
        "id": 1061892,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605142182
    },
    {
        "content": "<p><code>zulip-tornado</code> restart every time</p>",
        "id": 1061893,
        "sender_full_name": "wekun",
        "timestamp": 1605142216
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>tail -f /var/log/zulip/errors.log\nf&quot;Django cannot connect to Tornado server ({tornado_uri}); try restarting&quot;)\n</code></pre></div>",
        "id": 1061894,
        "sender_full_name": "wekun",
        "timestamp": 1605142282
    },
    {
        "content": "<p>Is there anything in /var/log/zulip/tornado.log (not errors.log)?</p>",
        "id": 1061895,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605142318
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>tail -f /var/log/zulip/tornado.log\nTornado server is running at http://127.0.0.1:9993/\nINFO [:9993] Tornado 9993  50.1% busy over the past 18.0 seconds\n...\n</code></pre></div>",
        "id": 1061896,
        "sender_full_name": "wekun",
        "timestamp": 1605142471
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>netstat -tlpn\n(Not all processes could be identified, non-owned process info\n will not be shown, you would have to be root to see it all.)\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\ntcp        0      0 127.0.0.1:5672          0.0.0.0:*               LISTEN      -\ntcp        0      0 127.0.0.1:25672         0.0.0.0:*               LISTEN      -\ntcp        0      0 127.0.0.1:9993          0.0.0.0:*               LISTEN      17790/python3\ntcp        0      0 127.0.0.1:6379          0.0.0.0:*               LISTEN      -\ntcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      180/nginx: worker p\ntcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -\ntcp        0      0 127.0.0.1:5432          0.0.0.0:*               LISTEN      -\ntcp        0      0 0.0.0.0:25              0.0.0.0:*               LISTEN      -\ntcp        0      0 0.0.0.0:443             0.0.0.0:*               LISTEN      180/nginx: worker p\ntcp6       0      0 ::1:6379                :::*                    LISTEN      -\ntcp6       0      0 :::9292                 :::*                    LISTEN      -\ntcp6       0      0 :::80                   :::*                    LISTEN      180/nginx: worker p\ntcp6       0      0 :::4369                 :::*                    LISTEN      -\ntcp6       0      0 :::22                   :::*                    LISTEN      -\ntcp6       0      0 ::1:5432                :::*                    LISTEN      -\ntcp6       0      0 :::25                   :::*                    LISTEN      -\ntcp6       0      0 :::443                  :::*                    LISTEN      180/nginx: worker p\n</code></pre></div>",
        "id": 1061897,
        "sender_full_name": "wekun",
        "timestamp": 1605142513
    },
    {
        "content": "<p>You’ll need to look at more than two lines of tornado.log.</p>",
        "id": 1061898,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605142528
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>tail -f /var/log/zulip/tornado.log\n2020-11-12 00:51:25.228 INFO [:9993] Tornado 9993   0.0% busy over the past  0.0 seconds\n2020-11-12 00:51:45.879 INFO [zr:9993] 181.94.47.38    GET     400   8ms (db: 3ms/2q) (+start: 14.3s) /json/events (11@root via ZulipElectron)\n2020-11-12 00:51:45.879 INFO [zr:9993] status=400, data=b&#39;{&quot;result&quot;:&quot;error&quot;,&quot;msg&quot;:&quot;Bad event queue id: 1605142226:0&quot;,&quot;queue_id&quot;:&quot;1605142226:0&quot;,&quot;code&quot;:&quot;BAD_EVENT_QUEUE_ID&quot;}\\n&#39;, uid=11@root\n2020-11-12 00:51:45.880 INFO [:9993] Tornado 9993  81.8% busy over the past 20.7 seconds\n2020-11-12 00:51:45.983 INFO [zr:9993] 127.0.0.1       POST    200   3ms (db: 1ms/2q) /api/v1/events/internal [1605142260:0/0] (11@root via internal)\n2020-11-12 00:51:46.396 INFO [zr:9993] 127.0.0.1       POST    200   4ms (db: 1ms/1q) /api/v1/events/internal [1605142260:0/0] (11@root via internal)\n2020-11-12 00:51:55.242 INFO [:9993] Tornado 9993  56.3% busy over the past 30.0 seconds\nTornado server is running at http://127.0.0.1:9993/\n2020-11-12 00:52:13.622 INFO [:9993] Tornado 9993 loaded 0 event queues in 0.000s\n2020-11-12 00:52:13.625 INFO [:9993] Tornado 9993   0.0% busy over the past  0.0 seconds\n2020-11-12 00:52:43.686 INFO [:9993] Tornado 9993   0.0% busy over the past 30.0 seconds\n2020-11-12 00:52:50.311 INFO [:9993] Tornado 9993   6.7% busy over the past 36.7 seconds\n2020-11-12 00:52:50.360 INFO [zr:9993] 127.0.0.1       POST    200  40ms (db: 2ms/3q) /api/v1/events/internal [1605142332:0/0] (11@root via internal)\n2020-11-12 00:52:50.534 INFO [zr:9993] 127.0.0.1       POST    200   2ms (db: 1ms/1q) /api/v1/events/internal [1605142332:0/0] (11@root via internal)\nTornado server is running at http://127.0.0.1:9993/\n2020-11-12 00:53:16.861 INFO [:9993] Tornado 9993 loaded 0 event queues in 0.000s\n2020-11-12 00:53:16.863 INFO [:9993] Tornado 9993   0.0% busy over the past  0.0 seconds\n2020-11-12 00:53:25.839 INFO [:9993] Tornado 9993   0.0% busy over the past  9.0 seconds\n2020-11-12 00:53:34.821 INFO [zr:9993] 181.94.47.38    GET     400   6ms (db: 2ms/2q) (+start: 37ms) /json/events (11@root via ZulipElectron)\n2020-11-12 00:53:34.822 INFO [zr:9993] status=400, data=b&#39;{&quot;result&quot;:&quot;error&quot;,&quot;msg&quot;:&quot;Bad event queue id: 1605142332:0&quot;,&quot;queue_id&quot;:&quot;1605142332:0&quot;,&quot;code&quot;:&quot;BAD_EVENT_QUEUE_ID&quot;}\\n&#39;, uid=11@root\n2020-11-12 00:53:34.823 INFO [:9993] Tornado 9993  50.1% busy over the past 18.0 seconds\nTornado server is running at http://127.0.0.1:9993/\n2020-11-12 00:54:05.793 INFO [:9993] Tornado 9993 loaded 0 event queues in 0.003s\n2020-11-12 00:54:05.798 INFO [:9993] Tornado 9993   0.0% busy over the past  0.0 seconds\n2020-11-12 00:54:18.110 INFO [:9993] Tornado 9993   0.0% busy over the past 12.3 seconds\n2020-11-12 00:54:18.146 INFO [zr:9993] 127.0.0.1       POST    200  19ms (db: 6ms/3q) (+start: 8ms) /api/v1/events/internal [1605142417:0/0] (11@root via internal)\n2020-11-12 00:54:18.341 INFO [zr:9993] 127.0.0.1       POST    200   5ms (db: 1ms/1q) /api/v1/events/internal [1605142417:0/0] (11@root via internal)\n2020-11-12 00:54:51.515 INFO [:9993] Tornado 9993  70.7% busy over the past 45.7 seconds\n2020-11-12 00:54:58.679 INFO [:9993] Tornado 9993  61.1% busy over the past 52.9 seconds\nTornado server is running at http://127.0.0.1:9993/\n2020-11-12 00:55:22.015 INFO [:9993] Tornado 9993 loaded 0 event queues in 0.001s\n2020-11-12 00:55:22.064 INFO [:9993] Tornado 9993   0.0% busy over the past  0.0 seconds\nTornado server is running at http://127.0.0.1:9993/\n2020-11-12 00:55:47.850 INFO [:9993] Tornado 9993 loaded 0 event queues in 0.003s\n2020-11-12 00:55:48.072 INFO [:9993] Tornado 9993   0.0% busy over the past  0.0 seconds\n</code></pre></div>",
        "id": 1061899,
        "sender_full_name": "wekun",
        "timestamp": 1605142569
    },
    {
        "content": "<p>Is it possible that your server is running out of memory and OOM-killing the Tornado server repeatedly? Check <code>dmesg</code>.</p>",
        "id": 1061902,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605142761
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>dmesg\n...\nMemory cgroup stats for /lxc/102/ns/user.slice/user-111.slice/user-runtime-dir@111.service: cache:108KB rss:0KB rss_huge:0KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB swap:0KB inactive_anon:0KB active_anon:0KB inactive_file:0KB active_file:0KB unevictable:0KB\n...\nMemory cgroup out of memory: Kill process 30835 (python3) score 52 or sacrifice child\n[24797770.289920] Killed process 30835 (python3) total-vm:318272kB, anon-rss:110544kB, file-rss:0kB, shmem-rss:0kB\n[24797770.292982] oom_reaper: reaped process 30835 (python3), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB\n</code></pre></div>",
        "id": 1061903,
        "sender_full_name": "wekun",
        "timestamp": 1605142973
    },
    {
        "content": "<p>you are right Anders.</p>",
        "id": 1061904,
        "sender_full_name": "wekun",
        "timestamp": 1605143004
    },
    {
        "content": "<p>the server is a LXC</p>",
        "id": 1061905,
        "sender_full_name": "wekun",
        "timestamp": 1605143027
    },
    {
        "content": "<p>Yeah that would do it. Sorry for the initial confusion. How much RAM do you have?</p>",
        "id": 1061906,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605143028
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>free -h\n              total        used        free      shared  buff/cache   available\nMem:          2,0Gi       859Mi        36Mi       1,1Gi       1,1Gi       1,2Gi\nSwap:            0B          0B          0B\n</code></pre></div>",
        "id": 1061907,
        "sender_full_name": "wekun",
        "timestamp": 1605143066
    },
    {
        "content": "<p>2 GB might be barely enough if you have few users and nothing else running on the server, but we recommend more.</p>",
        "id": 1061908,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605143155
    },
    {
        "content": "<p>ok. Whats is your recomendation, please?</p>",
        "id": 1061909,
        "sender_full_name": "wekun",
        "timestamp": 1605143200
    },
    {
        "content": "<p>And given that it’s LXC, I’m guessing there’s something else running on it. If it’s easy to add more RAM, try that; perhaps start with 4 GB and see how that goes.</p>",
        "id": 1061910,
        "sender_full_name": "Anders Kaseorg",
        "timestamp": 1605143271
    },
    {
        "content": "<p>we are 20 (aprox)</p>",
        "id": 1061911,
        "sender_full_name": "wekun",
        "timestamp": 1605143311
    },
    {
        "content": "<p>ok, THANKS Anders!</p>",
        "id": 1061912,
        "sender_full_name": "wekun",
        "timestamp": 1605143349
    },
    {
        "content": "<p>all is OK now!</p>",
        "id": 1061914,
        "sender_full_name": "wekun",
        "timestamp": 1605143783
    },
    {
        "content": "<p>Thanks very much!</p>",
        "id": 1061916,
        "sender_full_name": "wekun",
        "timestamp": 1605143835
    },
    {
        "content": "<p>I wonder if there's a way we could make OOM issues like this more discoverable (E.g. by having them result in something in <code>/var/log/zulip/errors.log</code>, with a link to docs?)</p>",
        "id": 1065900,
        "sender_full_name": "Tim Abbott",
        "timestamp": 1605749839
    }
]