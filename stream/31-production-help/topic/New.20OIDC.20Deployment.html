<html>
<head><meta charset="utf-8"><title>New OIDC Deployment · production help · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://rht.github.io/czo-archive/stream/31-production-help/index.html">production help</a></h2>
<h3>Topic: <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/New.20OIDC.20Deployment.html">New OIDC Deployment</a></h3>

<hr>

<base href="https://chat.zulip.org">

<head><link href="https://rht.github.io/czo-archive/style.css" rel="stylesheet"></head>

<a name="1217290"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/New%20OIDC%20Deployment/near/1217290" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Glen Barney <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/New.20OIDC.20Deployment.html#1217290">(Jun 23 2021 at 22:41)</a>:</h4>
<p>Hi All - <span class="user-mention" data-user-id="7">@Tim Abbott</span> asked me to post a problem report here, regarding OIDC deployment.  <span class="user-mention" data-user-id="10349">@Mateusz Mandera</span> has been leading an effort to help us integrate Zulip with our in-house OIDC server.  Mateusz committed some new code, which we applied via the upgrade-from-GIT method, to enable support for OIDC in our particular setup.</p>
<p>The OIDC integration itself works wonderfully, but we have a very strange problem which is that the first time anyone tries to join our Zulip instance via OIDC, Zulip experiences hangs and crashes.  We have tried this both with accounts that previously existed on Zulip (i.e. accounts created by the email-registration method, and then accessed via OIDC), and with accounts which did not exist, and for which OIDC was the initial contact.   In all cases, the problem occurs on the first OIDC encounter for any particular account, whether it existed previously or not.</p>
<p>When a user approaches Zulip via OIDC, the user is handed off to our OIDC server's login, the login is successful, the user is handed back to Zulip on the /complete/oidc pathway, with that URL appearing in the user's browser (which shows me that the browser got the redirect from our OIDC server successfully and was trying to recontact Zulip)... but Zulip then hangs.  It hangs for about 10-15 seconds, and then terminates with the Zulip custom 500-Internal-Server-Error green screen.</p>
<p>After multiple attempts - we've observed anywhere between two and six attempts being necessary, the user will finally manage to get back in to Zulip, logged in correctly via OIDC.   Once the user reaches that point, everything performs flawlessly into the future.  The user can log out of Zulip, and/or the OIDC source, can wipe cookies, whatever you like, subsequent login attempt are always flawless and fast.  Once the user gets in to Zulip via OIDC the first time, the problem for that user is never seen again.   But every user who approaches Zulip via OIDC absolutely sees some variant of this issue the first time around.  Only those who push through succeed.</p>
<p>The only information that seemed relevant that I could find was in /var/log/zulip/django.log</p>
<p>The last log entry before the crash (I think this was when I clicked the "Login via OIDC" button, and, thought it may be pointless, I'm truncating out IP addresses a bit):</p>
<blockquote>
<p>2021-06-06 23:03:11.010 INFO [zr] 173.0.0.0    GET     302  33ms (db: 4ms/3q) /login/oi<br>
dc/ (unauth@root via Mozilla)<br>
[pid: 7849|app: 0|req: 7/21] 173.0.0.0 () {52 vars in 1052 bytes} [Sun Jun  6 23:03:10<br>
2021] GET /login/oidc/?subdomain=&amp;is_signup=0&amp;multiuse_object_key=&amp;next=%2F =&gt; generated 0<br>
bytes in 34 msecs (HTTP/2.0 302) 8 headers in 691 bytes (1 switches on core 0)</p>
</blockquote>
<p>Then, in the very same log, when I came back to Zulip from the OIDC Server (note the different date format here):</p>
<blockquote>
<p>Sun Jun  6 23:03:32 2021 - <strong>* HARAKIRI ON WORKER 5 (pid: 7849, try: 1) </strong>*<br>
Sun Jun  6 23:03:32 2021 - HARAKIRI !!! worker 5 status !!!<br>
Sun Jun  6 23:03:32 2021 - HARAKIRI [core 0] 173.8.0.0 - GET /complete/oidc/?code=8c5c096c7bed451d94e41b7837dd673f&amp;state=KWNejjjyJeRtQjM5PxE9amT8CmpUf7Tl since 1623020591<br>
Sun Jun  6 23:03:32 2021 - HARAKIRI !!! end of worker 5 status !!!</p>
</blockquote>
<p>followed immediately by:</p>
<blockquote>
<p>2021-06-06 23:03:32.741 INFO [zr] 173.0.0.0    GET     404  57ms (db: 1ms/1q) /favicon.ico (unauth@root via Mozilla)<br>
[pid: 7846|app: 0|req: 4/22] 173.0.0.0 () {50 vars in 937 bytes} [Sun Jun  6 23:03:32 2021] GET /favicon.ico =&gt; generated 0 bytes in 57 msecs (HTTP/2.0 404) 4 headers in 0 bytes (0 switches on core 0)</p>
</blockquote>
<p>and then (no date stamp on this line):</p>
<blockquote>
<p>DAMN ! worker 5 (pid: 7849) died, killed by signal 9 :( trying respawn ...<br>
Respawned uWSGI worker 5 (new pid: 8113)</p>
</blockquote>
<p>followed by:</p>
<blockquote>
<p>2021-06-06 23:03:45.011 INFO [zr] 2003:db:7740:4142:: POST    200   7ms (db: 1ms/2q) /json/users/me/presence (23@root via ZulipElectron/5.7.0)<br>
[pid: 7846|app: 0|req: 5/23] 2003:db:7740:4142:: () {62 vars in 1407 bytes} [Sun Jun  6 23:03:45 2021] POST /json/users/me/presence =&gt; generated 407 bytes in 8 msecs (HTTP/2.0 200) 9 headers in 320 bytes (1 switches on core 0)<br>
2021-06-06 23:04:32.700 INFO [zr] 173.0.0.0    GET     302   1ms / (unauth@root via Mozilla)<br>
[pid: 7845|app: 0|req: 2/24] 173.0.0.0 () {52 vars in 904 bytes} [Sun Jun  6 23:04:32 2021] GET / =&gt; generated 0 bytes in 2 msecs (HTTP/2.0 302) 5 headers in 153 bytes (1 switches on core 0)<br>
2021-06-06 23:04:32.798 INFO [zr] 173.0.0.0    GET     200  59ms (db: 1ms/1q) /login/ (unauth@root via Mozilla)<br>
[pid: 7848|app: 0|req: 7/25] 173.0.0.0 () {52 vars in 916 bytes} [Sun Jun  6 23:04:32 2021] GET /login/ =&gt; generated 11525 bytes in 60 msecs (HTTP/2.0 200) 7 headers in 440 bytes (1 switches on core 0)</p>
</blockquote>
<p>where I was dumped back to the login screen.</p>
<p>It seems like multiple sources might be writing to the log file.  The only other log files being updated were server.log and tornado.log, but there were no anomalies in either of those logs.</p>
<p>Tim suggested that posting here would be good to get, as he said, more eyes on this problem, I apologize if I picked the wrong stream (I even reviewed the non-auto-sub streams, but this one seems most relevant.)  I'd be grateful for any insights and will try to answer any questions if possible.  </p>
<p>Thank you all for reading!</p>



<a name="1217297"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/New%20OIDC%20Deployment/near/1217297" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Abbott <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/New.20OIDC.20Deployment.html#1217297">(Jun 23 2021 at 22:55)</a>:</h4>
<p><span class="user-mention" data-user-id="20903">@Glen Barney</span> this is the right place!</p>



<a name="1217298"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/New%20OIDC%20Deployment/near/1217298" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Abbott <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/New.20OIDC.20Deployment.html#1217298">(Jun 23 2021 at 22:56)</a>:</h4>
<p>The <code>uwsgi</code> processes being killed is not a failure mode we see often.</p>



<a name="1217299"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/New%20OIDC%20Deployment/near/1217299" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Abbott <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/New.20OIDC.20Deployment.html#1217299">(Jun 23 2021 at 22:56)</a>:</h4>
<p>Is it easy to watch <code>top</code> while the connection is happening and see if the process's memory is spiking or something?</p>



<a name="1217300"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/New%20OIDC%20Deployment/near/1217300" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Abbott <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/New.20OIDC.20Deployment.html#1217300">(Jun 23 2021 at 22:58)</a>:</h4>
<p>Most of the code for this integration is in python-social-auth, so one possible path forward is to do a bit of print-debugging in that library to see where the crash is happening.</p>



<a name="1217301"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/New%20OIDC%20Deployment/near/1217301" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Abbott <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/New.20OIDC.20Deployment.html#1217301">(Jun 23 2021 at 22:59)</a>:</h4>
<p>It does kinda look like the crash is happening inside <code>python-social-auth</code> code for processing the response.</p>



<a name="1217567"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/New%20OIDC%20Deployment/near/1217567" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mateusz Mandera <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/New.20OIDC.20Deployment.html#1217567">(Jun 24 2021 at 09:05)</a>:</h4>
<p>Hi <span class="user-mention" data-user-id="20903">@Glen Barney</span>! Can you try with this patch so that we have logs for the time to query the various endpoints to see if that could be the culprit after all? Perhaps the query time on the /userinfo endpoint is super long when a user is signing up or something like that?</p>
<div class="codehilite" data-code-language="Diff"><pre><span></span><code><span class="gh">diff --git a/zproject/backends.py b/zproject/backends.py</span>
<span class="gh">index db33e5575e..cdb5429bdb 100644</span>
<span class="gd">--- a/zproject/backends.py</span>
<span class="gi">+++ b/zproject/backends.py</span>
<span class="gu">@@ -2334,7 +2334,8 @@ class SAMLAuthBackend(SocialAuthMixin, SAMLAuth):</span>

         return result

<span class="gd">-</span>
<span class="gi">+import time</span>
<span class="gi">+from social_core.utils import cache</span>
 @external_auth_method
 class GenericOpenIdConnectBackend(SocialAuthMixin, OpenIdConnectAuth):
     name = "oidc"
<span class="gu">@@ -2385,6 +2386,50 @@ class GenericOpenIdConnectBackend(SocialAuthMixin, OpenIdConnectAuth):</span>
         ]


<span class="gi">+    @cache(ttl=86400)</span>
<span class="gi">+    def oidc_config(self):</span>
<span class="gi">+        s = time.time()</span>
<span class="gi">+        url = self.OIDC_ENDPOINT + '/.well-known/openid-configuration'</span>
<span class="gi">+        self.logger.info("Getting %s", url)</span>
<span class="gi">+        response =  self.get_json(url)</span>
<span class="gi">+        self.logger.info(f"Time to get {url}: {time.time()-s}")</span>
<span class="gi">+        return response</span>
<span class="gi">+</span>
<span class="gi">+    def request_access_token(self, *args, **kwargs):</span>
<span class="gi">+        """</span>
<span class="gi">+        Retrieve the access token. Also, validate the id_token and</span>
<span class="gi">+        store it (temporarily).</span>
<span class="gi">+        """</span>
<span class="gi">+        s = time.time()</span>
<span class="gi">+        url = "/token"</span>
<span class="gi">+        self.logger.info("Getting %s", url)</span>
<span class="gi">+        response = self.get_json(*args, **kwargs)</span>
<span class="gi">+        self.logger.info(f"Time to get {url}: {time.time()-s}")</span>
<span class="gi">+        self.id_token = self.validate_and_return_id_token(</span>
<span class="gi">+            response['id_token'],</span>
<span class="gi">+            response['access_token']</span>
<span class="gi">+        )</span>
<span class="gi">+        return response</span>
<span class="gi">+</span>
<span class="gi">+    def user_data(self, access_token, *args, **kwargs):</span>
<span class="gi">+        s = time.time()</span>
<span class="gi">+        url = self.userinfo_url()</span>
<span class="gi">+        self.logger.info("Getting %s", url)</span>
<span class="gi">+        response = self.get_json(url, headers={</span>
<span class="gi">+            'Authorization': 'Bearer {0}'.format(access_token)</span>
<span class="gi">+        })</span>
<span class="gi">+        self.logger.info(f"Time to get {url}: {time.time()-s}")</span>
<span class="gi">+        return response</span>
<span class="gi">+</span>
<span class="gi">+    @cache(ttl=86400)</span>
<span class="gi">+    def get_remote_jwks_keys(self):</span>
<span class="gi">+        s = time.time()</span>
<span class="gi">+        url = self.jwks_uri()</span>
<span class="gi">+        self.logger.info("Getting %s", url)</span>
<span class="gi">+        response = self.request(url)</span>
<span class="gi">+        self.logger.info(f"Time to get {url}: {time.time()-s}")</span>
<span class="gi">+        return json.loads(response.text)['keys']</span>
<span class="gi">+</span>
 def validate_otp_params(
     mobile_flow_otp: Optional[str] = None, desktop_flow_otp: Optional[str] = None
 ) -&gt; None:
</code></pre></div>
<p>The logs will be in <code>/var/log/zulip/auth.log</code></p>



<a name="1217568"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/New%20OIDC%20Deployment/near/1217568" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mateusz Mandera <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/New.20OIDC.20Deployment.html#1217568">(Jun 24 2021 at 09:06)</a>:</h4>
<p>This patch is just copy-paste from python-social-auth code with logging added.</p>



<a name="1218023"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/New%20OIDC%20Deployment/near/1218023" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Glen Barney <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/New.20OIDC.20Deployment.html#1218023">(Jun 24 2021 at 19:32)</a>:</h4>
<p><span class="user-mention" data-user-id="7">@Tim Abbott</span> <span class="user-mention" data-user-id="10349">@Mateusz Mandera</span> Yes I can do this.  We tried to delete a user and recreate it to test, but that didn't work.  I'm now being asked to wipe and reinitialize the entire database (or wipe the server and start it over) to allow for recording and capture of retesting.</p>
<p>I note in searches that there was a delete-reinitialize-database command being discussed.  Is that something I can do?  If not, is there a manual way to wipe the database?   I get on a plane late tonight and really want to move this forward before I leave, but if I have to reload the entire server it's going to be tight.  Hoping for a faster way to just reinit the database?</p>
<p>Once I know that I'll either apply the patch in place, or I'll wipe and reload the entire server, but it may be a week or two (when I get back from vacation) before I can make everything work (ugh)  Sorry!</p>



<a name="1218113"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/New%20OIDC%20Deployment/near/1218113" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Glen Barney <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/New.20OIDC.20Deployment.html#1218113">(Jun 24 2021 at 21:48)</a>:</h4>
<p>Okay, just to make sure I'm not the hold up, I'm doing a full wipe and reload of the (virtual) server now.  I'll then apply the patch, and have everyone retry.</p>



<hr><p>Last updated: Oct 02 2023 at 04:38 UTC</p>
</html>