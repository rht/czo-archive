<html>
<head><meta charset="utf-8"><title>Tornado Multiprocess · production help · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://rht.github.io/czo-archive/stream/31-production-help/index.html">production help</a></h2>
<h3>Topic: <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html">Tornado Multiprocess</a></h3>

<hr>

<base href="https://chat.zulip.org">

<head><link href="https://rht.github.io/czo-archive/style.css" rel="stylesheet"></head>

<a name="683280"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683280" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> YI Jeong <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683280">(Jan 16 2019 at 19:12)</a>:</h4>
<p>Is tornado multiprocessing available in 1.9.1?<br>
It seems to add the tornado_processes value to the application_server section of the zulip.conf configuration file and then run the puppet-apply script.<br>
But I did not find clear information in the guide document. So ask if it is actually available.</p>



<a name="683284"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683284" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Abbott <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683284">(Jan 16 2019 at 19:17)</a>:</h4>
<p><span class="user-mention" data-user-id="3667">@YI Jeong</span> it is, though not documented because it requires a bit of a fork to use and it's not useful if you only have one organization, since the current setup shards by realm.</p>



<a name="683287"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683287" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> YI Jeong <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683287">(Jan 16 2019 at 19:24)</a>:</h4>
<p>Okay.. Each process is responsible for each realm.<br>
So, unfortunately, it will not help us. thank you.</p>



<a name="683289"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683289" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Abbott <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683289">(Jan 16 2019 at 19:26)</a>:</h4>
<p><span class="user-mention" data-user-id="3667">@YI Jeong</span> how large is your organization?</p>



<a name="683290"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683290" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Abbott <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683290">(Jan 16 2019 at 19:26)</a>:</h4>
<p>We have done considerable work towards the single-realm version of that, but it's not in a state where one can use it without collaboration from the core team (available via a support contract)</p>



<a name="683291"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683291" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Abbott <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683291">(Jan 16 2019 at 19:26)</a>:</h4>
<p>But if your organization is not huge, you may not need it.</p>



<a name="683297"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683297" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> YI Jeong <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683297">(Jan 16 2019 at 19:32)</a>:</h4>
<p>Our organization is not large.<br>
So I think that it will be possible to solve it simply (some setting change, tuning), but it is not easy. <span class="emoji emoji-1f644" title="rolling eyes">:rolling_eyes:</span> <br>
<a href="user_uploads/2/71/OhqY21kNWghUiAbWPekNlhMG/pasted_image.png" target="_blank" title="user_uploads/2/71/OhqY21kNWghUiAbWPekNlhMG/pasted_image.png">pasted image</a><br>
<a href="user_uploads/2/70/LB8O-jBYwd9q-su3coQcnKVg/pasted_image.png" target="_blank" title="user_uploads/2/70/LB8O-jBYwd9q-su3coQcnKVg/pasted_image.png">pasted image</a></p>
<div class="message_inline_image"><a href="user_uploads/2/71/OhqY21kNWghUiAbWPekNlhMG/pasted_image.png" target="_blank" title="pasted image"><img src="user_uploads/2/71/OhqY21kNWghUiAbWPekNlhMG/pasted_image.png"></a></div><div class="message_inline_image"><a href="user_uploads/2/70/LB8O-jBYwd9q-su3coQcnKVg/pasted_image.png" target="_blank" title="pasted image"><img src="user_uploads/2/70/LB8O-jBYwd9q-su3coQcnKVg/pasted_image.png"></a></div>



<a name="683436"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683436" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Abbott <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683436">(Jan 16 2019 at 21:58)</a>:</h4>
<p><span class="user-mention" data-user-id="3667">@YI Jeong</span> are you having a Tornado performance problem?  I would not expect one with that many users.</p>



<a name="683521"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683521" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> YI Jeong <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683521">(Jan 17 2019 at 05:21)</a>:</h4>
<p><span class="user-mention" data-user-id="7">@Tim Abbott</span> <br>
The tornado process used a lot of resources, and the logs looked like it might need to load-balance.</p>
<div class="codehilite"><pre><span></span>2019-01-17 05:16:57.665 INFO [] Tornado  65.9% busy over the past 43.2 seconds
2019-01-17 05:17:53.161 INFO [] Tornado  96.7% busy over the past 55.5 seconds
2019-01-17 05:17:58.187 INFO [] Tornado  90.9% busy over the past 59.6 seconds
</pre></div>



<a name="683522"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683522" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> YI Jeong <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683522">(Jan 17 2019 at 05:23)</a>:</h4>
<p>What does 'lp' mean in the log below?</p>
<div class="codehilite"><pre><span></span>2019-01-17 05:16:15.658 INFO [zr] 123.123.123.123   GET     200   6ms (lp: 5.7s) (db: 1ms/1q) /json/events [1547669980:469/1/message] (ID@domain via ZulipElectron)
</pre></div>



<a name="683524"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683524" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> YI Jeong <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683524">(Jan 17 2019 at 05:50)</a>:</h4>
<p>The problem seems to be simple.<br>
In the idle state, Zulip is no problem at all, but when there are more users (about 300 users), message transmission is delayed. However, the CPU, memory, and IO resources of the server are in a sufficient state. (Except Tornado?)</p>
<p>I think I just need to find where this delay occurs.<br>
First, I will migrate the data after a clean install and monitor performance once again.</p>
<p>top</p>
<div class="codehilite"><pre><span></span>Tasks: 200 total,   3 running, 197 sleeping,   0 stopped,   0 zombie
%Cpu(s): 28.0 us,  2.9 sy,  0.0 ni, 67.6 id,  0.3 wa,  0.0 hi,  1.3 si,  0.0 st
KiB Mem : 16421148 total,  1455076 free,  3949104 used, 11016968 buff/cache
KiB Swap:  4189180 total,  4094396 free,    94784 used. 11964092 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
43750 zulip     20   0  496392 263224  21304 R  93.0  1.6 182:33.04 python3 /home/zulip/deployments/current/manage.py runtornado 127.0.0.1:9993
43768 zulip     20   0  337780 105252  21432 S  59.3  0.6  87:14.66 python3 /home/zulip/deployments/current/manage.py process_queue --queue_name=user_activity
43891 zulip     20   0  498480 151156  18820 R  21.5  0.9  50:43.77 /home/zulip/deployments/current/zulip-current-venv/bin/uwsgi --ini /etc/zulip/uwsgi.ini
 1175 rabbitmq  20   0 4480968 121528   5240 S  15.9  0.7 229:59.57 /usr/lib/erlang/erts-7.3/bin/beam.smp -W w -A 64 -P 1048576 -K true -B i -- -root /usr/lib/erlang -progname erl -- -home /var/lib/rabbitmq -- -pa /usr/lib/rabbitmq/li+
  854 root      20   0   61240  13712   7024 S   8.9  0.1  88:29.59 /usr/bin/python /usr/bin/supervisord -n -c /etc/supervisor/supervisord.conf
43890 zulip     20   0  502140 155064  19452 S   8.9  0.9  31:19.92 /home/zulip/deployments/current/zulip-current-venv/bin/uwsgi --ini /etc/zulip/uwsgi.ini
43759 zulip     20   0  337656 105160  21688 S   7.0  0.6  15:46.27 python3 /home/zulip/deployments/current/manage.py process_queue --queue_name=user_presence
43889 zulip     20   0  495636 148672  19452 S   7.0  0.9  20:37.46 /home/zulip/deployments/current/zulip-current-venv/bin/uwsgi --ini /etc/zulip/uwsgi.ini
 1041 redis     20   0   57800  22712   2124 S   6.6  0.1  88:44.13 /usr/bin/redis-server 127.0.0.1:6379
43888 zulip     20   0  507652 159044  17940 S   6.6  1.0  15:10.69 /home/zulip/deployments/current/zulip-current-venv/bin/uwsgi --ini /etc/zulip/uwsgi.ini
  862 nobody    20   0  748976 304996   2128 S   4.6  1.9  55:45.23 /usr/bin/memcached -m 996 -p 11211 -u nobody -l 127.0.0.1 -o slab_reassign,slab_automove,lru_crawler,lru_maintainer,maxconns_fast,hash_algorithm=murmur3
43886 zulip     20   0  506044 157104  17612 S   4.0  1.0  10:23.54 /home/zulip/deployments/current/zulip-current-venv/bin/uwsgi --ini /etc/zulip/uwsgi.ini
43887 zulip     20   0  509656 161036  17632 S   3.6  1.0  12:01.58 /home/zulip/deployments/current/zulip-current-venv/bin/uwsgi --ini /etc/zulip/uwsgi.ini
 1151 zulip     20   0  162876  27636   4724 S   1.7  0.2  11:42.81 nginx: worker process
 1153 zulip     20   0  161860  26692   4692 S   1.7  0.2  11:14.08 nginx: worker process
 1148 zulip     20   0  162024  26920   4724 S   1.3  0.2  11:15.86 nginx: worker process
 1149 zulip     20   0  162668  27448   4708 S   1.3  0.2  12:06.62 nginx: worker process
 1150 zulip     20   0  162660  27464   4716 S   1.0  0.2  11:47.04 nginx: worker process
 1146 zulip     20   0  162592  27632   4720 S   0.7  0.2  11:17.58 nginx: worker process
 1147 zulip     20   0  162532  27604   4716 S   0.7  0.2  11:59.25 nginx: worker process
 1152 zulip     20   0  162664  27580   4724 S   0.7  0.2  11:21.92 nginx: worker process
43765 zulip     20   0  337644 105096  21656 S   0.7  0.6   1:40.15 python3 /home/zulip/deployments/current/manage.py process_queue --queue_name=user_activity_interval
    7 root      20   0       0      0      0 S   0.3  0.0   8:22.70 [rcu_sched]
 1130 snmp      20   0   67828   4444   2588 S   0.3  0.0   3:25.79 /usr/sbin/snmpd -Lsd -Lf /dev/null -u snmp -g snmp -I -smux mteTrigger mteTriggerConf -p /run/snmpd.pid
 1393 root      20   0 1287476  19708   4360 S   0.3  0.1  24:35.61 SMSAGENT
27069 infra     20   0   96940   4300   3328 S   0.3  0.0   0:00.89 sshd: infra@pts/1
43758 zulip     20   0  336920 103524  20836 S   0.3  0.6   0:06.50 python3 /home/zulip/deployments/current/manage.py process_queue --queue_name=slow_queries
</pre></div>


<p>server.log</p>
<div class="codehilite"><pre><span></span>2019-01-17 05:42:03.192 INFO [zr] 123.124.222.100   SOCKET  200   5ms (db: 1ms/1q) /socket/auth [transport=websocket] (usera@domain via ?)
2019-01-17 05:42:03.195 INFO [zr] 123.123.201.23    GET     200   7ms (lp: 40ms) (db: 1ms/1q) /json/events [1547669980:4/1/message] (userb@domain via ZulipElectron)
2019-01-17 05:42:03.204 INFO [zr] 123.124.222.100   POST    200   7ms /json/report/send_times [46860ms/9803ms/(unknown)ms/echo:True/diff:False] (usera@domain via website)
2019-01-17 05:42:03.205 INFO [zr] 123.124.222.161   GET     200   6ms (lp: 40ms) (db: 1ms/1q) /json/events [1547669980:1471/1/message] (userc@domain via ZulipElectron)
2019-01-17 05:42:03.207 INFO [zr] 123.123.201.23    SOCKET  200   1ms (lp: 120ms) (db: 1ms/1q) /socket/service_request [transport=websocket, queue_delay: 63ms/19ms, service_time: 37ms] (userb@domain via ?)
2019-01-17 05:42:03.208 INFO [zr] 123.123.201.23    SOCKET  200   0ms (db: 1ms/1q) /socket/close [transport=websocket] (userb@domain via ?)
2019-01-17 05:42:03.220 INFO [zr] 123.124.226.46    SOCKET  200  12ms (db: 2ms/2q) /socket/auth [transport=websocket] (userd@domain via ?)
2019-01-17 05:42:03.232 INFO [] Tornado  99.8% busy over the past 54.5 seconds
2019-01-17 05:42:03.243 INFO [zr] 123.124.226.46    POST    200   7ms /json/report/send_times [42606ms/15268ms/(unknown)ms/echo:True/diff:False] (userd@domain via ZulipElectron)
2019-01-17 05:42:03.272 INFO [zr] 123.124.222.24    GET     200   9ms (lp: 1.6s) /json/events [1547669980:2326/1/message] (usere@domain via website)
2019-01-17 05:42:03.272 INFO [zr] 123.124.226.76    POST    200   7ms /json/report/narrow_times [51ms/297ms/297ms] (userf@domain via website)
2019-01-17 05:42:03.274 INFO [zr] 123.123.100.28    GET     200   6ms (lp: 240ms) /api/v1/events [1547669980:2784/1/message] (chat-bot@domain via ZulipPython)
2019-01-17 05:42:03.276 INFO [zr] 123.124.222.23    GET     200   6ms (lp: 1.2s) /json/events [1547669980:31/1/message] (userg@domain via website)
2019-01-17 05:42:03.279 INFO [zr] 123.124.222.18    GET     200   7ms (lp: 165ms) /json/events [1547669980:99/1/message] (userh@domain via website)
2019-01-17 05:42:03.280 INFO [zr] 123.124.222.101   GET     200   8ms (lp: 608ms) /json/events [1547669980:53/1/message] (useri@domain via ZulipElectron)
2019-01-17 05:42:03.283 INFO [zr] 123.124.222.17    GET     200   7ms (lp: 1.0s) /json/events [1547669980:1230/1/message] (userj@domain via ZulipElectron)
2019-01-17 05:42:03.289 INFO [zr] 123.124.222.102   GET     200   6ms (lp: 5.2s) /json/events [1547669980:87/1/message] (userk@domain via ZulipElectron)
2019-01-17 05:42:03.293 INFO [zr] 123.124.222.100   GET     200  10ms (lp: 169ms) /json/events [1547669980:2482/1/message] (usera@domain via website)
2019-01-17 05:42:03.298 INFO [zr] 123.124.222.40    GET     200   6ms (lp: 1.0s) /json/events [1547669980:1923/1/message] (userl@domain via ZulipElectron)
2019-01-17 05:42:03.301 INFO [zr] 123.124.222.100   SOCKET  200   1ms (lp: 78ms) /socket/service_request [transport=websocket, queue_delay: 5ms/36ms, service_time: 36ms] (usera@domain via ?)
2019-01-17 05:42:03.316 INFO [zr] 123.124.222.100   SOCKET  200   1ms (lp: 91ms) /socket/service_request [transport=websocket, queue_delay: 4ms/41ms, service_time: 45ms] (usera@domain via ?)
2019-01-17 05:42:03.319 INFO [zr] 123.124.222.100   SOCKET  200   6ms (lp: 93ms) /socket/service_request [transport=websocket, queue_delay: 6ms/22ms, service_time: 60ms] (usera@domain via ?)
2019-01-17 05:42:03.328 INFO [zr] 127.0.0.1       POST    200   3ms /api/v1/events/internal [1547669980:2785/0] (chat-bot@domain via internal)
2019-01-17 05:42:03.341 INFO [zr] 123.124.222.23    GET     200   6ms /json/events [1547669980:31/2] (userg@domain via website)
2019-01-17 05:42:03.353 INFO [zr] 123.124.222.17    GET     200   6ms /json/events [1547669980:1230/2] (userj@domain via ZulipElectron)
2019-01-17 05:42:03.355 INFO [zr] 123.124.222.100   POST    200  14ms /json/report/send_times [39464ms/39423ms/(unknown)ms/echo:True/diff:False] (usera@domain via website)
2019-01-17 05:42:03.363 INFO [zr] 127.0.0.1       POST    200   3ms /api/v1/events/internal [1547669980:2785/0] (chat-bot@domain via internal)
</pre></div>



<a name="683766"></a>
<h4><a href="https://chat.zulip.org#narrow/stream/31-production%20help/topic/Tornado%20Multiprocess/near/683766" class="zl"><img src="https://rht.github.io/czo-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tim Abbott <a href="https://rht.github.io/czo-archive/stream/31-production-help/topic/Tornado.20Multiprocess.html#683766">(Jan 17 2019 at 19:30)</a>:</h4>
<p><span class="user-mention" data-user-id="3667">@YI Jeong</span> OK, thanks for sharing that data.  It does seem you are having Tornado load issues.  I'm a bit puzzled why the average request processing times are so long.  I'm about to head out on a trip but I can do some investigation next week.</p>



<hr><p>Last updated: Oct 02 2023 at 04:38 UTC</p>
</html>